{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2rkzJNtGLMCw",
    "outputId": "276b0a1b-2505-4257-9967-be81523d4c5f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Trainer, TrainingArguments, DistilBertForSequenceClassification, DistilBertTokenizerFast\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('stopwords')\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbD-LKe7FwvD"
   },
   "source": [
    "# **Project Overview**\n",
    "**1. Objective**: The goal of this project is to build a sentiment analysis model using the Neural Network, BiLSTM, and DistilBERT transformer model to classify IMDb movie reviews into positive and negative sentiments. The project aims to automate the sentiment classification process, enabling businesses to analyze customer feedback on movies at scale.\n",
    "\n",
    "**2. Dataset**: The data is [IMDB movie reviews](https://www.kaggle.com/datasets/pawankumargunjan/imdb-review) on Kaggle, which contain 50,000 labeled reviews (25,000 for training, 25,000 for testing). Each review is labeled as either positive(1) or negative(0). Both train and test set are balanced dataset with 50-50 for two classes. Each has 3 columns: sentence (film review in English), sentiment (ratings), polarity (sentimnet label).\n",
    "\n",
    "**3. Model Description**:\n",
    "- DistilBERT is a balance between computational efficiency and performance. DistilBERT is a smaller version of BERT while retaining 97% language understanding. The model consists DistilBERT followed by a classification head that predicts the sentiment (positive or negative). The model is fine-tuned for 3 epochs on IMDB training dataset.\n",
    "\n",
    "- BiLSTM: is a type of recurrent neural network (RNN) that processes input data in both forward and backward directions. This allows the model to capture context from both the past and the future in sequence data, which is particularly useful for tasks like sentiment classification. It improves accuracy compared to a unidirectional LSTM.\n",
    "\n",
    "- A Dense Network: consists of fully connected layers where each neuron is connected to every neuron in the previous layer. It directly processes the input features (e.g., word embeddings) through these layers to predict sentiment. The final Dense layer outputting the sentiment prediction.\n",
    "\n",
    "**4. Result**:\n",
    "- The DistilBERT achieved **93% F1, and 93% Accuracy** on the balanced test set, indicating strong performance for sentiment analysis.\n",
    "- LSTM: 86% F1, and 86% Accuracy which is pretty good.\n",
    "- Dense: 1.00 Recall but achieved only 50% Accuracy and 66.68% F1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sm4A3NmkAVGW"
   },
   "source": [
    "# **I. Import Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1bqJrBKs1ul6",
    "outputId": "25fe9167-f9da-4bdb-cbec-330dab08c692"
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"pawankumargunjan/imdb-review\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ybGpKe0m2BJQ",
    "outputId": "b963a2d5-4858-4d17-dece-f8e807c0f145"
   },
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk(path):\n",
    "    print(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2bfJi7yI21bH"
   },
   "outputs": [],
   "source": [
    "def load_directory_data(directory):\n",
    "    data = {}\n",
    "    data[\"sentence\"] = []\n",
    "    data[\"sentiment\"] = []\n",
    "    for file_path in os.listdir(directory):\n",
    "        with tf.io.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
    "            data[\"sentence\"].append(f.read())\n",
    "            data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
    "    return pd.DataFrame.from_dict(data)\n",
    "\n",
    "# Merge positive and negative examples, add a polarity column and shuffle.\n",
    "def load_dataset(directory):\n",
    "    pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
    "    neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
    "    pos_df[\"polarity\"] = 1\n",
    "    neg_df[\"polarity\"] = 0\n",
    "    return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6h_tMa2s23zJ"
   },
   "outputs": [],
   "source": [
    "# Get the train and test data\n",
    "train = load_dataset('/root/.cache/kagglehub/datasets/pawankumargunjan/imdb-review/versions/3/aclImdb/train')\n",
    "test = load_dataset('/root/.cache/kagglehub/datasets/pawankumargunjan/imdb-review/versions/3/aclImdb/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "sN1FK5pl3J9p",
    "outputId": "673fb4cb-2eb8-454e-8677-93421bedfd1d"
   },
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "BxupniZx30id",
    "outputId": "5d91ba29-cff2-4a7b-f69d-1c6bd7aaf9c3"
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zCwYIezl_j3L",
    "outputId": "3046f73d-9335-4fc8-a496-5e76ccb6a0d8"
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pDK6aRaqeIAe",
    "outputId": "407f489f-9422-47a5-ec11-ac456cf52436"
   },
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34pM2-CG35vx"
   },
   "source": [
    "# **II. EDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xWF7h-ZH4Ht"
   },
   "source": [
    "**Film Rating Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 247
    },
    "id": "6UGzbYdygSW0",
    "outputId": "dd1b32f0-112b-4705-9736-c26fcf84cb4a"
   },
   "outputs": [],
   "source": [
    "# Get the rating distribution of Train and Test\n",
    "\n",
    "# Convert rating from object to number\n",
    "train['sentiment'] = train['sentiment'].astype(int)\n",
    "test['sentiment'] = test['sentiment'].astype(int)\n",
    "\n",
    "# Create data for pie chart\n",
    "rating_train_agg = train.groupby('sentiment')['sentiment'].count().reset_index(name='count')\n",
    "rating_test_agg = test.groupby('sentiment')['sentiment'].count().reset_index(name='count')\n",
    "\n",
    "# Subplot for rating of train and test set\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].pie(rating_train_agg['count'], labels=rating_train_agg['sentiment'], autopct='%1.1f%%', startangle=90)\n",
    "axes[0].axis('equal')\n",
    "axes[0].set_title('Training Data')\n",
    "\n",
    "axes[1].pie(rating_test_agg['count'], labels=rating_test_agg['sentiment'], autopct='%1.1f%%', startangle=90)\n",
    "axes[1].axis('equal')\n",
    "axes[1].set_title('Test Data')\n",
    "\n",
    "plt.suptitle(\"Rating for movies on Train and Test set\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oPBBtXRjCFR"
   },
   "source": [
    "The distribution Rating on Train and Test data are similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ccbx5SXzH-wJ"
   },
   "source": [
    "**Word Length Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 247
    },
    "id": "UMureMlf39Rr",
    "outputId": "a18a5458-5d8b-4209-abbd-26f448c37895"
   },
   "outputs": [],
   "source": [
    "# Plot the length distribution of Train and Test\n",
    "\n",
    "# Add text length column\n",
    "train['word_length'] = train['sentence'].apply(lambda x: len(x.split()))\n",
    "test['word_length'] = test['sentence'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Suplot for length of text\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "sns.histplot(train['word_length'], bins=50, kde=True, ax=axes[0])\n",
    "axes[0].set_title('Training Data')\n",
    "axes[0].set_xlabel('Word Length')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "sns.histplot(test['word_length'], bins=50, kde=True, color='red', ax=axes[1])\n",
    "axes[1].set_title('Test Data')\n",
    "axes[1].set_xlabel('Word Length')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "plt.suptitle(\"Distribution of Word Lengths in Training & Test Data\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9OmIqyuMXkc"
   },
   "source": [
    "Most reviews have less than 500 words, however, there are some very long reviews with more than 2500 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHZtzspzIH6B"
   },
   "source": [
    "**Top 10 Words of Negative and Positive Review**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "id": "WmAjQOqeIbe-",
    "outputId": "97bc4594-4804-48fd-bfcd-1dde51836d37"
   },
   "outputs": [],
   "source": [
    "# Get 10 most common words in Train data for Negative and Positive review\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "extra_stopwords = {\"'s\", \"n't\", \"'m\", \"'re\", \"br\"}\n",
    "stop_words.update(extra_stopwords)\n",
    "\n",
    "def get_top_words_by_label(dataframe, label, stop_words, n=10):\n",
    "    \"\"\"Get top N words for a specific sentiment label\"\"\"\n",
    "    subset = dataframe[dataframe['polarity'] == label]\n",
    "\n",
    "    all_text = ' '.join(subset['sentence'].tolist()).lower()\n",
    "    words = re.findall(r\"\\b[\\w']+\\b\", all_text)\n",
    "\n",
    "    # Filter words -  Remove nonsense and high frenquency word\n",
    "    filtered_words = [\n",
    "        word for word in words\n",
    "        if word not in stop_words\n",
    "        and len(word) > 2\n",
    "        and not word.isdigit()\n",
    "        and word not in {\"movie\", \"film\", \"one\", \"really\", \"time\", \"story\", \"would\", \"see\"}\n",
    "    ] # These words are not nonsense as a, an, the but they do not provide any insight -> delete\n",
    "\n",
    "    word_counts = Counter(filtered_words)\n",
    "    top_words = pd.DataFrame(word_counts.most_common(n),\n",
    "                            columns=['word', f'count_{\"positive\" if label else \"negative\"}'])\n",
    "\n",
    "    return top_words\n",
    "\n",
    "top_positive = get_top_words_by_label(train, 1, stop_words)\n",
    "top_negative = get_top_words_by_label(train, 0, stop_words)\n",
    "\n",
    "# Display both dataframes\n",
    "print(\"Top Words in Positive Reviews:\")\n",
    "display(top_positive)\n",
    "\n",
    "print(\"\\nTop Words in Negative Reviews:\")\n",
    "display(top_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "id": "GVH8vfPDJiXG",
    "outputId": "2b1be67e-cef5-4710-f141-2febd00907de"
   },
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "sns.barplot(data=top_positive, x='word', y='count_positive', ax=ax1, color='green')\n",
    "ax1.set_title('Top Words - Positive Reviews')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "sns.barplot(data=top_negative, x='word', y='count_negative', ax=ax2, color='red')\n",
    "ax2.set_title('Top Words - Negative Reviews')\n",
    "ax2.set_ylabel('Count')\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mViGNb4yJlf9"
   },
   "source": [
    "**Word Cloud for both Negative and Positive Review**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 752
    },
    "id": "yJmzc6Z3JqoM",
    "outputId": "6e08feaf-9c14-4d96-f287-dbe8433c1834"
   },
   "outputs": [],
   "source": [
    "# Get the Word Cloud for two labels in Train set\n",
    "from wordcloud import WordCloud\n",
    "def generate_label_wordcloud(dataframe, label, stop_words, title):\n",
    "    subset = dataframe[dataframe['polarity'] == label]\n",
    "    text = ' '.join(subset['sentence'].tolist()).lower()\n",
    "\n",
    "    words = re.findall(r\"\\b[\\w']+\\b\", text)\n",
    "    filtered_words = [\n",
    "        word for word in words\n",
    "        if word not in stop_words\n",
    "        and len(word) > 2\n",
    "        and not word.isdigit()\n",
    "        and word not in {\"movie\", \"film\", \"one\", \"really\", \"time\", \"story\", \"would\", \"see\"}\n",
    "    ]\n",
    "    text = ' '.join(filtered_words)\n",
    "\n",
    "    # Generate and plot word cloud\n",
    "    wordcloud = WordCloud(width=800, height=400,\n",
    "                         background_color='white',\n",
    "                         colormap='viridis' if label else 'plasma').generate(text)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Generate word clouds for both labels\n",
    "generate_label_wordcloud(train, 1, stop_words,\n",
    "                        \"Positive Reviews (Label 1) Word Cloud - Training Set\")\n",
    "print(\"=\"*100)\n",
    "generate_label_wordcloud(train, 0, stop_words,\n",
    "                        \"Negative Reviews (Label 0) Word Cloud - Training Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fNLiHf-jFNE7",
    "outputId": "19a92049-0a38-4887-a500-279f115e38dd"
   },
   "outputs": [],
   "source": [
    "# Distribution of word length\n",
    "print('Distribution of word length in train data')\n",
    "print(train['word_length'].describe())\n",
    "print()\n",
    "print('Distribution of word length in test data')\n",
    "print(test['word_length'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4au2_pN_bhs4"
   },
   "source": [
    "75% examples of both train and test set has length under or equal 284. However, the max length is 2470 which is really far beyond the rest of data. I will delete the examples with length more than 284 from the dataset to reduce computational expense (in terms of number of training examples, and the length of tokens) while remain most dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EX_0mWqGb_Dr"
   },
   "outputs": [],
   "source": [
    "train = train[train['word_length'] <= 284].reset_index(drop=True)\n",
    "test = test[test['word_length'] <= 284].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 536
    },
    "id": "VRqScqFP601y",
    "outputId": "ddca3f40-22b8-4bae-fb1d-b91b31bd0c6d"
   },
   "outputs": [],
   "source": [
    "# Have a look at customer review on films\n",
    "pd.options.display.max_colwidth = 200\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mRLaW8337Woe",
    "outputId": "db58ca57-bbc3-4964-c7ef-1fe3761eb9da"
   },
   "outputs": [],
   "source": [
    "# Have a closer look at a review\n",
    "print(f\"Sentiment Label for this review: {train.loc[0, 'sentiment']}\")\n",
    "print('-'*50)\n",
    "print(train.loc[0, 'sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oLbWRFxG7w0Z",
    "outputId": "9688c692-fa0a-418c-c988-b5b7a86b57eb"
   },
   "outputs": [],
   "source": [
    "print('Percentage of pos and neg in train data')\n",
    "print()\n",
    "print(train.polarity.value_counts(normalize=True).reset_index())\n",
    "print()\n",
    "print()\n",
    "print('Percentage of pos and neg in test data')\n",
    "print()\n",
    "print(test.polarity.value_counts(normalize=True).reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_5Ct3EJ9hU1"
   },
   "source": [
    "After deleting long sentence, both train and test data still have a balance of negative and positive review which is really good. And there is no need for resampling training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Za8_cH1h8uRW",
    "outputId": "34b8be0a-496a-4ed7-c95a-6ae67ed59750"
   },
   "outputs": [],
   "source": [
    "print(f\"Numner of example in Train data: {train.shape[0]}\")\n",
    "print(f\"Numner of example in Test data: {test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SE-zLE8x-U8a"
   },
   "source": [
    "# **III. Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9RNv7MAYKcXz"
   },
   "source": [
    "**Prepare Data for DistilBERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDv-hCz4lzW-"
   },
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "      # Tokenization with truncate and padding\n",
    "        self.encodings = tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=max_length\n",
    "        )\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "      # Tensor conversion\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.encodings['input_ids'][idx]),\n",
    "            'attention_mask': torch.tensor(self.encodings['attention_mask'][idx]),\n",
    "            'labels': torch.tensor(self.labels[idx])\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181,
     "referenced_widgets": [
      "5f26bf40c48e4e12a1718877c415d462",
      "e43ffbc91bf048468313118bc6677c9a",
      "b836c7497ee14c9e9dcb20845ece6515",
      "db6561c285df458da6d04272657b2879",
      "54f0ada2d86e4669b4209ed2da269871",
      "6d795f23a8be423c8133ab49ff40d9de",
      "12c6b4808ea84f398499afff7bc179f2",
      "2942cc65d2d744ea868059fe02afe617",
      "cda82b19e623477cacb6ca350d24be00",
      "67f2d84f1eee457392d5283cb7415e86",
      "8b456b8427b248a69ecd8874db300674",
      "7ca8cc364e3143bdaa43d97fdc1b884c",
      "a83b3530d8734ab4ac4ba1e527081840",
      "b97b586227404c4e9818fe40885c4eac",
      "3f4ae6d3910c4291a9ea198fb9d2bf7d",
      "9bb776eec6e240fe93dc88a8bec40182",
      "9e396f4d8f034052a8d746a884137afb",
      "6ce2d6b8746b4000bb6d3e1c73e69cff",
      "53cdbc04cf464ff28623751b59c953f2",
      "14776accdca5437fba70143f48b9140a",
      "85a17314d5ab41df8ba05b83a3e77a79",
      "dcd00d05e7114dc1bbc8b060b34da1dc",
      "844e4cc5f20d4eb1975af76cac7028f4",
      "85f454fc917c4b9b81d2bd7d5ca9c471",
      "9d99f1e0391f48cca93478bfc15f0a44",
      "7b0a0d07a96545a596cff648f942b196",
      "343a4984d6484c85a7a378f0ac09e9d4",
      "d895ad25aac246d7b4148c7007ea933c",
      "fbb1512f60ae4244838cd5440478a154",
      "7b0c874db53e4233b55dcca13a7b3110",
      "f95bb7c71c47448b8059f0278b6e9a15",
      "44f4e8ad00ca4946827d05a675e3dc0e",
      "b58c17e5063542a38de930ccea9e07b3",
      "b915edcc96ab47a395afcd6f1507516c",
      "be0eff22f9b44db7a5b464ae5e7f51bd",
      "2c267443f910469bb21b7ded974463ff",
      "27061dafe0f447639bd4599608155c5c",
      "ba27ad67759c43ddb5880d99095763e0",
      "79ecdfe226b6440bba25aefb205fe2e6",
      "e4f7514cc6384d66ac3081f1bae39334",
      "90472502a5ba42349dc1521b8503516e",
      "0110e2e8c1354662b3b3926d41ed8485",
      "75bc2635e4a6446db173ef9ad1e68d8c",
      "4de644f30bda4a92a845679e7310ef6a"
     ]
    },
    "id": "kLGidLbTnElx",
    "outputId": "cabe2290-296d-477b-90a5-f425cf4b710b"
   },
   "outputs": [],
   "source": [
    "# Get the max length for padding purpose\n",
    "max_length = max(max(train['word_length']), max(test['word_length']))\n",
    "max_length_set = int(max_length*1.2)\n",
    "print(f\"Max length: {max_length}\")\n",
    "print(f\"Max length set: {max_length_set}\")\n",
    "\n",
    "# Initialize tokenizer with max length\n",
    "bert_tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lmgNlLuTowb1"
   },
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "train_dataset = SentimentDataset(\n",
    "    train['sentence'].tolist(),\n",
    "    train['polarity'].tolist(),\n",
    "    bert_tokenizer,\n",
    "    max_length_set\n",
    ")\n",
    "\n",
    "test_dataset = SentimentDataset(\n",
    "    test['sentence'].tolist(),\n",
    "    test['polarity'].tolist(),\n",
    "    bert_tokenizer,\n",
    "    max_length_set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bQFFs8XiiXI_",
    "outputId": "fda6db2c-553f-44af-dbab-55f674232f9c"
   },
   "outputs": [],
   "source": [
    "# Have a look at train_dataset and its original sentence\n",
    "sample = train_dataset[0]\n",
    "\n",
    "print(\"Input IDs:\", sample['input_ids'])\n",
    "print(\"Attention Mask:\", sample['attention_mask'])\n",
    "print(\"Label:\", sample['labels'])\n",
    "\n",
    "# Get original sentence\n",
    "decoded_text = bert_tokenizer.decode(sample['input_ids'], skip_special_tokens=True)\n",
    "print(\"\\nDecoded Text:\", decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXKhK4VZKTXI"
   },
   "source": [
    "**Prepare Data for BiLSTM and Dense Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PRk9wEYcKSmd"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "MAX_NB_WORDS = 20000\n",
    "MAX_SEQUENCE_LENGTH = 256\n",
    "EMBED_DIM = 64\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 20\n",
    "\n",
    "# Tokenization\n",
    "keras_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    num_words=MAX_NB_WORDS,\n",
    "    oov_token='<OOV>',\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    ")\n",
    "keras_tokenizer.fit_on_texts(train['sentence'])\n",
    "\n",
    "X_train = pad_sequences(keras_tokenizer.texts_to_sequences(train['sentence']),\n",
    "                       maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "X_test = pad_sequences(keras_tokenizer.texts_to_sequences(test['sentence']),\n",
    "                      maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "y_train = train['polarity'].values\n",
    "y_test = test['polarity'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eE38cT7B4wb"
   },
   "source": [
    "# **IV. Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdyAvCzOK4AK"
   },
   "source": [
    "**First Model: Dense**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJ3Jmc08LPOl"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Callbacks setup\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ynf0z4CPK8DT"
   },
   "outputs": [],
   "source": [
    "model_dense = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(MAX_NB_WORDS + 1, 128, input_length=MAX_SEQUENCE_LENGTH),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_dense.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "dense_checkpoint = ModelCheckpoint(\n",
    "    'best_dense.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pIkYEEolLDh2",
    "outputId": "f528622a-a879-44ee-ce01-92590642aca1"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "history_dense = model_dense.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stop, dense_checkpoint],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWHng_X7LIDu"
   },
   "source": [
    "**Second Model: LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MFi0kDkDLK9S"
   },
   "outputs": [],
   "source": [
    "# Model definition\n",
    "model_bilstm = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(MAX_NB_WORDS + 1, EMBED_DIM, input_length=MAX_SEQUENCE_LENGTH),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_bilstm.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "bilstm_checkpoint = ModelCheckpoint(\n",
    "    'best_bilstm.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJTQOKLPLeju",
    "outputId": "c1c7aebb-fee1-49c1-dd27-6a05d085cd55"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "history_bilstm = model_bilstm.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stop, bilstm_checkpoint],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOdyVnZLLhgx"
   },
   "source": [
    "**Third Model: DistilBERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160,
     "referenced_widgets": [
      "ab9c95153858495c9d7bdb88cf8b6146",
      "5ffe9ac990e446cda4acd083bb4afd76",
      "d41518ca9f2749cdb0b02b20fb09f123",
      "7ffb1e9f939c4158b52657ff178a8ecc",
      "a4abd109127b42ddb48a1be3984d8426",
      "5f4c84aa688c42a68aa96e6706bae828",
      "28cff9e2279e43aba0a86f6170a345a0",
      "863386551df04e9d872740ed21642567",
      "284778644ec2461ba3189ae0d7cc28dd",
      "2a918db6763a4c638bbca01d6ddf652f",
      "f82b5d81152640229098e75a03717ca6"
     ]
    },
    "id": "t7Y0ObIwpHgG",
    "outputId": "fc23eda5-6ffc-42c5-e495-bfb05f58078f"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# Get DistilBERT\n",
    "\n",
    "# Version control setup\n",
    "MODEL_VERSION = \"v1\"\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "MODEL_SAVE_NAME = f\"sentiment_model_{MODEL_VERSION}_{TIMESTAMP}\"\n",
    "MODEL_SAVE_PATH = os.path.join('./saved_models', MODEL_SAVE_NAME)\n",
    "\n",
    "# Check for saved model, else get pre_trained model\n",
    "if os.path.exists(MODEL_SAVE_PATH):\n",
    "    print(f\"Loading existing model: {MODEL_SAVE_NAME}\")\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(MODEL_SAVE_PATH)\n",
    "else:\n",
    "    print(f\"Initializing new model: {MODEL_SAVE_NAME}\")\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(\n",
    "        'distilbert-base-uncased',\n",
    "        num_labels=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w40xNESQpi7_"
   },
   "outputs": [],
   "source": [
    "# Function for metric calcualtion\n",
    "def compute_metrics(p):\n",
    "    \"\"\"\n",
    "    Calculate multiple evaluation metrics for classification\n",
    "    Uses sklearn metrics for compatibility with Hugging Face outputs\n",
    "    \"\"\"\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(p.label_ids, preds),\n",
    "        'f1': f1_score(p.label_ids, preds),\n",
    "        'precision': precision_score(p.label_ids, preds),\n",
    "        'recall': recall_score(p.label_ids, preds)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EI_ZIIx86hFX",
    "outputId": "83a92f3b-235c-45be-a03a-2c29c8ac6bc3"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"ðŸŽ¯ Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"ðŸ’» Total GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"âš ï¸ Warning: No GPU detected, training will be slow!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "rkP5e5JFp3iI",
    "outputId": "70d2a53d-b5b1-4add-8cdc-10927eb56319"
   },
   "outputs": [],
   "source": [
    "# Only train if model doesn't exist\n",
    "if not os.path.exists(MODEL_SAVE_PATH):\n",
    "  # Training arguments\n",
    "  training_args = TrainingArguments(\n",
    "      output_dir='./results',          # Directory for checkpoints\n",
    "      num_train_epochs=3,\n",
    "      per_device_train_batch_size=64,  # Batch size in training\n",
    "      per_device_eval_batch_size=128,  # Batch size in evaluation\n",
    "      warmup_ratio=0.1,                # 10% of training steps for learning rate warmup\n",
    "      weight_decay=0.01,               # Regularization\n",
    "      learning_rate=2e-5,              # Small rate for fine-tuning\n",
    "      eval_strategy='epoch',           # Evaluate after each epoch\n",
    "      save_strategy='epoch',           # Save checkpoint after each epoch\n",
    "      load_best_model_at_end=True,\n",
    "      fp16=True,\n",
    "      report_to='none',                # Disable external services logging\n",
    "      optim='adamw_torch',\n",
    "      gradient_accumulation_steps=1,   # No accumulation needed with current batch size\n",
    "  )\n",
    "\n",
    "  # Trainer initialization\n",
    "  trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    "  )\n",
    "\n",
    "  # Training process and saving model\n",
    "  print(\"Starting training...\")\n",
    "  trainer.train()\n",
    "  print(\"Training completed! Saving model...\")\n",
    "  model.save_pretrained(MODEL_SAVE_PATH)\n",
    "  bert_tokenizer.save_pretrained(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FUFIKEcbFUqS"
   },
   "source": [
    "# **V. Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nF_EDEYnQhqE"
   },
   "outputs": [],
   "source": [
    "def evaluate_models(X_test, y_test, test_texts, test_labels, max_length_set):\n",
    "    '''Get metric of 3 models, putting into a dataframe, and then plotting confusion matrix'''\n",
    "    # Initialize results storage\n",
    "    metrics = []\n",
    "    predictions = {}\n",
    "\n",
    "    # Evaluate Dense Model\n",
    "    model_dense = tf.keras.models.load_model('best_dense.h5')\n",
    "    y_pred_dense = (model_dense.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "    metrics.append({\n",
    "        'Model': 'Dense Network',\n",
    "        'Accuracy': accuracy_score(y_test, y_pred_dense),\n",
    "        'Precision': precision_score(y_test, y_pred_dense),\n",
    "        'Recall': recall_score(y_test, y_pred_dense),\n",
    "        'F1': f1_score(y_test, y_pred_dense)\n",
    "    })\n",
    "    predictions['Dense'] = y_pred_dense\n",
    "\n",
    "    # Evaluate BiLSTM Model\n",
    "    model_bilstm = tf.keras.models.load_model('best_bilstm.h5')\n",
    "    y_pred_bilstm = (model_bilstm.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "    metrics.append({\n",
    "        'Model': 'BiLSTM',\n",
    "        'Accuracy': accuracy_score(y_test, y_pred_bilstm),\n",
    "        'Precision': precision_score(y_test, y_pred_bilstm),\n",
    "        'Recall': recall_score(y_test, y_pred_bilstm),\n",
    "        'F1': f1_score(y_test, y_pred_bilstm)\n",
    "    })\n",
    "    predictions['BiLSTM'] = y_pred_bilstm\n",
    "\n",
    "    # Evaluate DistilBERT\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(MODEL_SAVE_PATH)\n",
    "    bert_tokenizer = DistilBertTokenizerFast.from_pretrained(MODEL_SAVE_PATH)\n",
    "\n",
    "    # Recreate test dataset\n",
    "    bert_dataset = SentimentDataset(\n",
    "        test_texts,\n",
    "        test_labels,\n",
    "        bert_tokenizer,\n",
    "        max_length_set\n",
    "    )\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    test_loader = DataLoader(bert_dataset, batch_size=64, shuffle=False)\n",
    "    bert_preds = []\n",
    "    bert_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "            bert_preds.extend(preds.cpu().numpy())\n",
    "            bert_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    metrics.append({\n",
    "        'Model': 'DistilBERT',\n",
    "        'Accuracy': accuracy_score(bert_labels, bert_preds),\n",
    "        'Precision': precision_score(bert_labels, bert_preds),\n",
    "        'Recall': recall_score(bert_labels, bert_preds),\n",
    "        'F1': f1_score(bert_labels, bert_preds)\n",
    "    })\n",
    "    predictions['DistilBERT'] = bert_preds\n",
    "\n",
    "    # Create metrics dataframe\n",
    "    metrics_df = pd.DataFrame(metrics).set_index('Model')\n",
    "\n",
    "    # Plot confusion matrices\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "    for i, (name, pred) in enumerate(predictions.items()):\n",
    "        if name == 'DistilBERT':\n",
    "            labels = bert_labels\n",
    "        else:\n",
    "            labels = y_test\n",
    "\n",
    "        cm = confusion_matrix(labels, pred)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(ax=axes[i])\n",
    "        axes[i].set_title(f'{name} Confusion Matrix')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return metrics_df, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "2Cpr9xDKQx8R",
    "outputId": "368b6b5d-5852-4ce7-e302-2c70a26277bd"
   },
   "outputs": [],
   "source": [
    "# Run evaluation\n",
    "test_texts = test['sentence'].tolist()\n",
    "test_labels = test['polarity'].tolist()\n",
    "metrics_df, predictions = evaluate_models(X_test, y_test, test_texts, test_labels, max_length_set)\n",
    "\n",
    "# Display metrics\n",
    "print(\"Model Comparison Metrics:\")\n",
    "display(metrics_df.style.background_gradient(cmap='Blues', axis=0))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
